{"cells":[{"cell_type":"markdown","source":["#Power Plant ML Pipeline Application\nThis is an end-to-end example of using a number of different machine learning algorithms to solve a supervised regression problem.\n\n###Table of Contents\n- *Step 1: Business Understanding*\n- *Step 2: Extract-Transform-Load (ETL) Your Data*\n- *Step 3: Explore Your Data*\n- *Step 4: Visualize Your Data*\n- *Step 5: Data Preparation*\n- *Step 6: Data Modeling*\n\n\n*We are trying to predict power output given a set of readings from various sensors in a gas-fired power generation plant.  Power generation is a complex process, and understanding and predicting power output is an important element in managing a plant and its connection to the power grid.*\n\nMore information about Peaker or Peaking Power Plants can be found on Wikipedia https://en.wikipedia.org/wiki/Peaking_power_plant\n\n\nGiven this business problem, we need to translate it to a Machine Learning task.  The ML task is regression since the label (or target) we are trying to predict is numeric.\n\n\nThe example data is provided by UCI at [UCI Machine Learning Repository Combined Cycle Power Plant Data Set](https://archive.ics.uci.edu/ml/datasets/Combined+Cycle+Power+Plant)\n\nYou can read the background on the UCI page, but in summary we have collected a number of readings from sensors at a Gas Fired Power Plant\n\n(also called a Peaker Plant) and now we want to use those sensor readings to predict how much power the plant will generate.\n\n\nMore information about Machine Learning with Spark can be found in the programming guide in the [SparkML Guide](https://spark.apache.org/docs/latest/mllib-guide.html)\n\n\n*Please note this example only works with Spark version 1.4 or higher*"],"metadata":{}},{"cell_type":"code","source":["assert int(sc.version.replace(\".\", \"\")) >= 140, \"Spark 1.4.0+ is required to run this notebook. Please attach it to a Spark 1.4.0+ cluster.\""],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":["##Step 1: Business Understanding\nThe first step in any machine learning task is to understand the business need. \n\nAs described in the overview we are trying to predict power output given a set of readings from various sensors in a gas-fired power generation plant.\n\nThe problem is a regression problem since the label (or target) we are trying to predict is numeric"],"metadata":{}},{"cell_type":"markdown","source":["##Step 2: Extract-Transform-Load (ETL) Your Data\n\nNow that we understand what we are trying to do, the first step is to load our data into a format we can query and use.  This is known as ETL or \"Extract-Transform-Load\".  We will load our file from Amazon s3.\n\nNote: Alternatively we could upload our data using \"Databricks Menu > Tables > Create Table\", assuming we had the raw files on our local computer.\n\n%md Our data is available on Amazon s3 at the following path:  \n`dbfs:/databricks-datasets/power-plant/data`\n\n**ToDo:** Let's start by printing the first 5 lines of the file.  \n*Hint*: To read the file into an RDD use `sc.textFile(\"dbfs:/databricks-datasets/power-plant/data\")`  \n*Hint*: Then you will need to figure out how to `take` and print the first 5 lines of the RDD."],"metadata":{}},{"cell_type":"code","source":["rawTextRdd = sc.textFile(\"dbfs:/databricks-datasets/power-plant/data\")\nfor line in rawTextRdd.take(5):\n    print(line)\n"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":["The file is a .tsv (Tab Seperated Values) file of floating point numbers.  \n\nOur schema definition from UCI appears below:\n\n- AT = Atmospheric Temperature in C\n- V = Exhaust Vacuum Speed\n- AP = Atmospheric Pressure\n- RH = Relative Humidity\n- PE = Power Output.  This is the value we are trying to predict given the measurements above.\n\n\n**ToDo:** Transform the RDD so that each row is a tuple of float values.  Then print the first 5 rows.  \n*Hint:* Use filter to exclude lines that start with AT to remove the header.  \n*Hint:* Use map to transform each line into a PowerPlantRow of data fields.  \n*Hint:* Use python's str.split break up each line into individual fields."],"metadata":{}},{"cell_type":"code","source":["from collections import namedtuple\nPowerPlantRow=namedtuple(\"PowerPlantRow\", [\"AT\", \"V\", \"AP\", \"RH\", \"PE\"])\nrawDataRdd=rawTextRdd\\\n  .map(lambda x: x.split(\"\\t\"))\\\n  .filter(lambda line: line[0] != \"AT\")\\\n  .map(lambda line: PowerPlantRow(float(line[0]), float(line[1]), float(line[2]), float(line[3]), float(line[4])))\nrawDataRdd.take(5)"],"metadata":{},"outputs":[],"execution_count":7}],"metadata":{"name":"Power-Solution1-ETL","notebookId":9134},"nbformat":4,"nbformat_minor":0}
