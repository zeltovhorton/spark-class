{"cells":[{"cell_type":"markdown","source":["# Binary Classification Algorithms with Pipelines API\n\nIn this notebook, we will test out the Binary Classification algorithms available in the ML Pipelines API using the Adult dataset. The Pipelines API provides higher-level API built on top of DataFrames for constructing ML pipelines. You can read more about the ML Pipelines API in the [programming guide](http://spark.apache.org/docs/latest/mllib-guide.html#sparkml-high-level-apis-for-ml-pipelines).\n\n####Table of Contents\n- Dataset Review\n- Load Data\n- Data Preprocessing\n- Creation and Evaluation of Models\n  - Logistic Regression\n  - Decision Trees\n  - Random Forest\n- Deployment"],"metadata":{}},{"cell_type":"markdown","source":["####Dataset Review\n\nThe Adult dataset is publicly available at the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Adult). This data was obtained from the Census, and consists of information about 48842 individuals and their annual income. We will use this information to predict if an individual earns >50k a year or <=50K a year. The dataset is rather clean, and consists of both numeric and categorical variables.\n\nAttribute Information:\n- age: continuous\n- workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked\n- fnlwgt: continuous\n- education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc...\n- education-num: continuous\n- marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent...\n- occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners...\n- relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried\n- race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black\n- sex: Female, Male. \n- capital-gain: continuous\n- capital-loss: continuous\n- hours-per-week: continuous\n- native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany...\n\n\nTarget/Label:\n- <=50K, >50K"],"metadata":{}},{"cell_type":"markdown","source":["####Load Data\nIn this example, we will read in the adult dataset that is mounted on the DBFS using the spark-csv package. We will use SQL to read in the data and rename the columns appropriately."],"metadata":{}},{"cell_type":"code","source":["# Filepath for adult dataset in DBFS\ndisplay(dbutils.fs.ls(\"databricks-datasets/adult/adult.data\"))"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["%sql DROP TABLE IF EXISTS adult"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["%sql\nCREATE TABLE adult (age double, workclass string, fnlwgt double, education string, education_num double, marital_status string, occupation string, relationship string, race string, sex string, capital_gain double, capital_loss double, hours_per_week double, native_country string, income string)\nUSING com.databricks.spark.csv\nOPTIONS (path \"/databricks-datasets/adult/adult.data\", header \"true\")"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"code","source":["dataset = sqlContext.table(\"adult\")"],"metadata":{},"outputs":[],"execution_count":7},{"cell_type":"code","source":["display(dataset)"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["#### Data Preprocessing\nSince we are going to try algorithms like Logistic Regression, we will have to convert the categorical variables in the dataset into numeric variables. There are 2 ways we can do this.\n\n\n- Category Indexing. This is basically assigning a numeric value to each category from {0, 1, 2, ...numCategories-1}. This introduces an implicit heirachy among your categories, and is more suitable for ordinal variables (eg: Poor: 0, Average: 1, Good: 2)\n- [One-Hot Encoding](https://en.wikipedia.org/wiki/One-hot). This converts categories into binary vectors with at most one positive value (eg: (Blue: 1, 0, 0), (Green: 0, 1, 0), (Red: 0, 0, 1))"],"metadata":{}},{"cell_type":"markdown","source":["Below is a quick example of what one-hot encoded variables will look like. The first column represents the categorical variable, and the second column represents the index assigned to each category value. The rest of the columns represent the resulting one-hot encoded binary vectors."],"metadata":{}},{"cell_type":"code","source":["colors = [('Blue', 0, 1, 0, 0), ('Green', 1, 0, 1, 0), ('Red', 2, 0 , 0 , 1)]\nrdd = sc.parallelize(colors)\ndf = sqlContext.createDataFrame(rdd, ['Colors', 'Index', 'OHE_attr1', 'OHE_attr2', 'OHE_attr3'])\ndisplay(df)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":["In this dataset, we have ordinal variables like education (Preschool - Doctorate), and also nominal variables like relationship (Wife, Husband, Own-child, etc). For simplicity's sake, we will use One-Hot Encoding to convert all categorical variables into binary vectors. It might be possible here to improve prediction accuracy by converting each categorical column with an appropriate method.\n\nHere, we will use a combination of [StringIndexer](http://spark.apache.org/docs/latest/ml-features.html#stringindexer) and [OneHotEncoder](http://spark.apache.org/docs/latest/ml-features.html#onehotencoder) to convert the categorical variables. The OneHotEncoder will return a [SparseVector](https://spark.apache.org/docs/latest/api/python/pyspark.mllib.html#pyspark.mllib.linalg.SparseVector)."],"metadata":{}},{"cell_type":"code","source":["###One-Hot Encoding\nfrom pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n  \ncategoricalColumns = [\"workclass\", \"education\", \"marital_status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"native_country\"]\nfor categoricalCol in categoricalColumns:\n  # Category Indexing with StringIndexer\n  stringIndexer = StringIndexer(inputCol=categoricalCol, outputCol=categoricalCol+\"Index\")\n  model = stringIndexer.fit(dataset)\n  indexed = model.transform(dataset)\n  # Use OneHotEncoder to convert categorical variables into binary SparseVectors\n  encoder = OneHotEncoder(inputCol=categoricalCol+\"Index\", outputCol=categoricalCol+\"classVec\")\n  encoded = encoder.transform(indexed)\n  dataset = encoded\n\nprint dataset.take(1)"],"metadata":{},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":["The above code basically indexes each categorical column using the StringIndexer, and then converts the indexed categories into one-hot encoded variables. The resulting output has the binary vectors appended to the end of each row."],"metadata":{}},{"cell_type":"markdown","source":["We use the StringIndexer() again here to encode our labels to label indices"],"metadata":{}},{"cell_type":"code","source":["# Convert label into label indices using the StringIndexer\nlabel_stringIdx = StringIndexer(inputCol = \"income\", outputCol = \"label\")\nlabel_model = label_stringIdx.fit(dataset)\nlabel_indexed = label_model.transform(dataset)\nprint label_indexed.take(1)\n"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["Next, we will use the VectorAssembler() to combine all the feature columns into a single vector column. This will include both the numeric columns and the one-hot encoded binary vector columns in our dataset."],"metadata":{}},{"cell_type":"code","source":["# Transform all features into a vector using VectorAssembler\nassembler = VectorAssembler(\n    inputCols=[\"age\",\"workclassclassVec\",\"fnlwgt\",\"educationclassVec\",\"education_num\",\"marital_statusclassVec\",\n               \"occupationclassVec\",\"relationshipclassVec\",\"raceclassVec\", \"sexclassVec\", \"capital_gain\", \"capital_loss\", \"hours_per_week\",\n               \"native_countryclassVec\"],\n    outputCol=\"features\")\noutput = assembler.transform(label_indexed)\n\n# Keep relevant columns\ndataset = output.select(\"label\", \"features\")\ndisplay(dataset)"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["### Randomly split data into training and test sets. set seed for reproducibility\n(trainingData, testData) = dataset.randomSplit([0.7, 0.3], seed = 100)\nprint trainingData.count()\nprint testData.count()"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":["#### Creation and Evaluation of Models\nWe are now ready to try out some of the Binary Classification Algorithms available in the new ML Pipelines API.\n\nOut of these algorithms, the below are currently also capable of supporting multiclass classification with the Python API:\n- Decision Trees\n- Random Forest\n\nThese are the general steps we will take to build our models:\n- Create initial model using the training set\n- Tune parameters with a ParamGrid and 5-fold Cross Validation\n- Evaluate the best model obtained from the Cross Validation using the test set\n\nWe will be using the BinaryClassificationEvaluator to evaluate our models. The default metric used here is [areaUnderROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve)."],"metadata":{}},{"cell_type":"markdown","source":["####Logistic Regression\n\nYou can read more about Logistic Regression from the Programming Guide [here](http://spark.apache.org/docs/latest/mllib-linear-methods.html#logistic-regression). In the new Pipelines API, we are now able to perform Elastic net regularization with Logistic Regression, as well as other linear methods.\n\n\nNote: As of Spark 1.5.0, The Python API does not yet support multiclass classification for Logistic Regression, but will be available in future."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.param import Param, Params\n\n# Create initial LogisticRegression model\nlr = LogisticRegression(labelCol=\"label\", featuresCol=\"features\", maxIter=10)\n\n# Train model with Training Data\nlrModel = lr.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":22},{"cell_type":"code","source":["# Make predictions on test data using the Transformer.transform() method.\n# LogisticRegression.transform() will only use the 'features' column.\npredictions = lrModel.transform(testData)"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["predictions.printSchema()"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"code","source":["# View model's predictions and probabilities of each prediction class\nselected = predictions.select(\"label\", \"prediction\", \"probability\")\ndisplay(selected)"],"metadata":{},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":["We can make use of the BinaryClassificationEvaluator method to evaluate our model. The Evaluator expects two input columns: (rawPrediction, label)."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\n\n# Evaluate model\nevaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\nevaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":27},{"cell_type":"markdown","source":["Note that the default metric for the BinaryClassificationEvaluator is areaUnderROC"],"metadata":{}},{"cell_type":"code","source":["evaluator.getMetricName()"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"markdown","source":["The evaluator currently accepts 2 kinds of metrics - areaUnderROC and areaUnderPR.\nWe can set it to areaUnderPR by using evaluator.setMetricName(\"areaUnderPR\")."],"metadata":{}},{"cell_type":"markdown","source":["Now we will try tuning the model with the ParamGridBuilder and the CrossValidator.\n\nIf you are unsure what params are available for tuning, you can use explainParams() to print a list of all params."],"metadata":{}},{"cell_type":"code","source":["print lr.explainParams()"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"markdown","source":["As we indicate 5 values for regParam, 4 values for maxIter, and 5 values for elasticNetParam, this grid will have 5 x 4 x 5 = 100 parameter settings for CrossValidator to choose from. We will create a 5-fold cross validator."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\n# Create ParamGrid for Cross Validation\nparamGrid = (ParamGridBuilder()\n             .addGrid(lr.regParam, [0.01, 0.1, 0.5, 1.0, 2.0])\n             .addGrid(lr.elasticNetParam, [0.0, 0.1, 0.5, 0.8, 1.0])\n             .addGrid(lr.maxIter, [1, 5, 10, 20])\n             .build())"],"metadata":{},"outputs":[],"execution_count":34},{"cell_type":"code","source":["# Create 5-fold CrossValidator\ncv = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n\n# Run cross validations\ncvModel = cv.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"code","source":["# Use test set here so we can measure the accuracy of our model on new data\npredictions = cvModel.transform(testData)"],"metadata":{},"outputs":[],"execution_count":36},{"cell_type":"code","source":["# cvModel uses the best model found from the Cross Validation\n# Evaluate best model\nevaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"markdown","source":["We can also access the model's feature weights and intercepts easily"],"metadata":{}},{"cell_type":"code","source":["print 'Model Intercept: ', cvModel.bestModel.intercept"],"metadata":{},"outputs":[],"execution_count":39},{"cell_type":"code","source":["from pyspark.sql import Row\n\nweights = cvModel.bestModel.weights\nrdd = sc.parallelize(weights)\nrdd = rdd.map(lambda x: Row(float(x)))\nweightsDF = sqlContext.createDataFrame(rdd, [\"Feature Weights\"])\ndisplay(weightsDF)"],"metadata":{},"outputs":[],"execution_count":40},{"cell_type":"code","source":["# View Best model's predictions and probabilities of each prediction class\nselected = predictions.select(\"label\", \"prediction\", \"probability\")\ndisplay(selected)"],"metadata":{},"outputs":[],"execution_count":41},{"cell_type":"markdown","source":["####Decision Trees\nYou can read more about Decision Trees from the Programming Guide [here](http://spark.apache.org/docs/latest/mllib-decision-tree.html).\n\nDecision Trees is a popular algorithm as it can handle categorical data and work with multiclass data."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.classification import DecisionTreeClassifier\n\n# Create initial Decision Tree Model\ndt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\", maxDepth=3)\n\n# Train model with Training Data\ndtModel = dt.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":43},{"cell_type":"markdown","source":["We can extract the number of nodes in our decision tree as well as the tree depth of our model."],"metadata":{}},{"cell_type":"code","source":["print \"numNodes = \", dtModel.numNodes\nprint \"depth = \", dtModel.depth"],"metadata":{},"outputs":[],"execution_count":45},{"cell_type":"code","source":["# Make predictions on test data using the Transformer.transform() method.\npredictions = dtModel.transform(testData)"],"metadata":{},"outputs":[],"execution_count":46},{"cell_type":"code","source":["predictions.printSchema()"],"metadata":{},"outputs":[],"execution_count":47},{"cell_type":"code","source":["# View model's predictions and probabilities of each prediction class\nselected = predictions.select(\"label\", \"prediction\", \"probability\")\ndisplay(selected)"],"metadata":{},"outputs":[],"execution_count":48},{"cell_type":"markdown","source":["We will evaluate our Decision Tree model with BinaryClassificationEvaluator."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\n\n# Evaluate model\nevaluator = BinaryClassificationEvaluator()\nevaluator.evaluate(predictions)\n"],"metadata":{},"outputs":[],"execution_count":50},{"cell_type":"markdown","source":["Entropy and the Gini coefficient are the supported measures of impurity for Decision Trees. This is set to Gini by default.\n\nThis can be changed by using model.setImpurity(\"Entropy\")."],"metadata":{}},{"cell_type":"code","source":["dt.getImpurity()"],"metadata":{},"outputs":[],"execution_count":52},{"cell_type":"markdown","source":["Now we will try tuning the model with the ParamGridBuilder and the CrossValidator.\n\nAs we indicate 6 values for maxDepth and 5 values for maxBin, this grid will have 6 * 5 = 30 parameter settings for CrossValidator to choose from. We will create a 5-fold CrossValidator."],"metadata":{}},{"cell_type":"code","source":["# Create ParamGrid for Cross Validation\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\nparamGrid = (ParamGridBuilder()\n             .addGrid(dt.maxDepth, [1,2,4,6,8,10])\n             .addGrid(dt.maxBins, [20,40,60,80,100])\n             .build())"],"metadata":{},"outputs":[],"execution_count":54},{"cell_type":"code","source":["# Create 5-fold CrossValidator\ncv = CrossValidator(estimator=dt, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n\n# Run cross validations\ncvModel = cv.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":55},{"cell_type":"code","source":["print \"numNodes = \", cvModel.bestModel.numNodes\nprint \"depth = \", cvModel.bestModel.depth"],"metadata":{},"outputs":[],"execution_count":56},{"cell_type":"code","source":["# Use test set here so we can measure the accuracy of our model on new data\npredictions = cvModel.transform(testData)"],"metadata":{},"outputs":[],"execution_count":57},{"cell_type":"code","source":["# cvModel uses the best model found from the Cross Validation\n# Evaluate best model\nevaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":58},{"cell_type":"code","source":["# View Best model's predictions and probabilities of each prediction class\nselected = predictions.select(\"label\", \"prediction\", \"probability\")\ndisplay(selected)"],"metadata":{},"outputs":[],"execution_count":59},{"cell_type":"markdown","source":["####Random Forest\n\nRandom Forests uses an ensemble of trees to improve model accuracy.\n\nYou can read more about Random Forest from the programming guide [here](http://spark.apache.org/docs/latest/mllib-ensembles.html#random-forests)."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.classification import RandomForestClassifier\n\n# Create an initial RandomForest model.\nrf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\")\n\n# Train model with Training Data\nrfModel = rf.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":61},{"cell_type":"code","source":["# Make predictions on test data using the Transformer.transform() method.\npredictions = rfModel.transform(testData)"],"metadata":{},"outputs":[],"execution_count":62},{"cell_type":"code","source":["predictions.printSchema()"],"metadata":{},"outputs":[],"execution_count":63},{"cell_type":"code","source":["# View model's predictions and probabilities of each prediction class\nselected = predictions.select(\"label\", \"prediction\", \"probability\")\ndisplay(selected)"],"metadata":{},"outputs":[],"execution_count":64},{"cell_type":"markdown","source":["We will evaluate our Random Forest model with BinaryClassificationEvaluator."],"metadata":{}},{"cell_type":"code","source":["from pyspark.ml.evaluation import BinaryClassificationEvaluator\n\n# Evaluate model\nevaluator = BinaryClassificationEvaluator()\nevaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":66},{"cell_type":"markdown","source":["Now we will try tuning the model with the ParamGridBuilder and the CrossValidator.\n\nAs we indicate 6 values for maxDepth, 5 values for maxBin, and 4 values for numTrees, this grid will have 6 x 5 x 4 = 120 parameter settings for CrossValidator to choose from. We will create a 5-fold CrossValidator."],"metadata":{}},{"cell_type":"code","source":["# Create ParamGrid for Cross Validation\nfrom pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n\nparamGrid = (ParamGridBuilder()\n             .addGrid(rf.maxDepth, [1,2,4,6,8,10])\n             .addGrid(rf.maxBins, [20,40,60,80,100])\n             .addGrid(rf.numTrees, [5,10,20,30])\n             .build())"],"metadata":{},"outputs":[],"execution_count":68},{"cell_type":"code","source":["# Create 5-fold CrossValidator\ncv = CrossValidator(estimator=rf, estimatorParamMaps=paramGrid, evaluator=evaluator, numFolds=5)\n\n# Run cross validations\ncvModel = cv.fit(trainingData)"],"metadata":{},"outputs":[],"execution_count":69},{"cell_type":"code","source":["# Use test set here so we can measure the accuracy of our model on new data\npredictions = cvModel.transform(testData)"],"metadata":{},"outputs":[],"execution_count":70},{"cell_type":"code","source":["# cvModel uses the best model found from the Cross Validation\n# Evaluate best model\nevaluator.evaluate(predictions)"],"metadata":{},"outputs":[],"execution_count":71},{"cell_type":"code","source":["# View Best model's predictions and probabilities of each prediction class\nselected = predictions.select(\"label\", \"prediction\", \"probability\")\ndisplay(selected)"],"metadata":{},"outputs":[],"execution_count":72},{"cell_type":"markdown","source":["#### Deployment\n\nAs Random Forest gives us the best areaUnderROC value, we will use the bestModel obtained from Random Forest for deployment, and use it to generate predictions on new data. In this example, we will simulate this by generating predictions on the entire dataset."],"metadata":{}},{"cell_type":"code","source":["bestModel = cvModel.bestModel"],"metadata":{},"outputs":[],"execution_count":74},{"cell_type":"code","source":["# Generate predictions for entire dataset\nfinalPredictions = bestModel.transform(dataset)"],"metadata":{},"outputs":[],"execution_count":75},{"cell_type":"code","source":["# Evaluate best model\nevaluator.evaluate(finalPredictions)"],"metadata":{},"outputs":[],"execution_count":76},{"cell_type":"markdown","source":["Since there are no userIds in this dataset, we will use the row indices as userIds as we know that each row corresponds to a unique individual. We will create a table of rowIndex and incomePrediction."],"metadata":{}},{"cell_type":"code","source":["display(finalPredictions)"],"metadata":{},"outputs":[],"execution_count":78},{"cell_type":"code","source":["finalPredictions.registerTempTable(\"finalPredictions\")"],"metadata":{},"outputs":[],"execution_count":79},{"cell_type":"code","source":["# View predictions with rowIndexes\ndeploymentTable = sql(\"SELECT prediction AS incomePrediction, ROW_NUMBER() OVER (ORDER BY prediction) AS rowIndexes FROM finalPredictions\")"],"metadata":{},"outputs":[],"execution_count":80},{"cell_type":"code","source":["display(deploymentTable)"],"metadata":{},"outputs":[],"execution_count":81},{"cell_type":"markdown","source":["In an operational environment, analysts may use a similar machine learning pipeline to obtain predictions on new data, organize it into a table and use it for lead targeting."],"metadata":{}},{"cell_type":"markdown","source":["We can also separate our deployment Table into 2 groups: income <=50k and income >50k."],"metadata":{}},{"cell_type":"code","source":["deploymentTable.registerTempTable(\"deploymentTable\")"],"metadata":{},"outputs":[],"execution_count":84},{"cell_type":"code","source":["#separate into 2 grps: <=50k, >50k\nlessthan50 = sql(\"SELECT incomePrediction, rowIndexes FROM deploymentTable WHERE incomePrediction = 0\")\nmorethan50 = sql(\"SELECT incomePrediction, rowIndexes FROM deploymentTable WHERE incomePrediction = 1\")"],"metadata":{},"outputs":[],"execution_count":85},{"cell_type":"code","source":["display(lessthan50)"],"metadata":{},"outputs":[],"execution_count":86},{"cell_type":"code","source":["display(morethan50)"],"metadata":{},"outputs":[],"execution_count":87},{"cell_type":"markdown","source":["Now we can target our users better!"],"metadata":{}},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":89}],"metadata":{"name":"Binary Classification Algorithms with Pipelines API","notebookId":9745},"nbformat":4,"nbformat_minor":0}
